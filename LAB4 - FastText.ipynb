{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/leand/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7d8330bc2984d4faca9e3efad0181b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from typing import Callable, Dict, Generator, List, Tuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext import vocab\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "import math\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfasttext\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mft\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Turn the dataset into a dataset compatible with Fastext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def preprocess(data : dict) -> dict:\n",
    "    '''Takes a document from a dataset, lowers the letters and\n",
    "    replace all punctuations by spaces'''\n",
    "    text = data[\"text\"]\n",
    "    for character in string.punctuation:\n",
    "        if character != \"-\":\n",
    "          text = text.replace(character, ' ')\n",
    "    data[\"text\"] = text.lower()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = dataset.map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ft_dataset(dataset, file):\n",
    "    with open(file, 'w') as f:\n",
    "        for d in dataset:\n",
    "            label = '__label__' + str(d['label'])\n",
    "            text = d['text']\n",
    "            f.write(label + ' ' + text + '\\n')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Train a FastText classifier with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft_file = to_ft_dataset(updated_dataset[\"train\"], \"ft_train_dataset.txt\")\n",
    "test_ft_file = to_ft_dataset(updated_dataset[\"test\"], \"ft_test_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"ft_train_dataset.txt\", 'r') as f:\n",
    "    train_lines = f.readlines()\n",
    "\n",
    "# Shuffle the training data\n",
    "shuffle(train_lines)\n",
    "with open(\"ft_train_dataset.txt\", 'w') as f:\n",
    "    f.writelines(train_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ft.train_supervised(input=\"ft_train_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p, _ = model.test(test_ft_file)\n",
    "print(\"L'accuracy est de:\", p, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Use the hyperparameters search functionality of FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"ft_train_dataset.txt\", 'r') as f:\n",
    "    data = []\n",
    "    labels = []\n",
    "    for line in f:\n",
    "        label, text = line.split(maxsplit=1)\n",
    "        data.append(text)\n",
    "        labels.append(label)\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(data, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Combine the data and labels into the format expected by FastText\n",
    "train = [f\"{label} {text.strip()}\\n\" for label, text in zip(Y_train, X_train)]\n",
    "val = [f\"{label} {text.strip()}\\n\" for label, text in zip(Y_valid, X_valid)]\n",
    "\n",
    "# Save the training and validation data to separate files\n",
    "with open('ft_train_dataset.txt', 'w') as f:\n",
    "    f.writelines(train)\n",
    "with open('ft_valid_dataset.txt', 'w') as f:\n",
    "    f.writelines(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameters = ft.train_supervised(input='ft_train_dataset.txt', autotuneValidationFile='ft_valid_dataset.txt', autotuneDuration=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, p, _ = model.test(\"ft_valid_dataset.txt\")\n",
    "print(\"L'accuracy est de:\", p, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
